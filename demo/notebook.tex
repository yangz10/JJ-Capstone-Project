
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Readme\_May\_22}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    

    \hypertarget{unspsc-code-project---rpi-capstone}{%
\section{UNSPSC code project - RPI
Capstone}\label{unspsc-code-project---rpi-capstone}}

\textbf{Tips} - This doc is only for Johnson \& Johnson internal Use. -
This doc can be divided into two parts: Brief Summary \& Technical
Document

    \hypertarget{part-i-brief-summay}{%
\subsection{Part I : Brief Summay}\label{part-i-brief-summay}}

    \textbf{All data are from Yilin Chen} (Thanks!)

\begin{itemize}
\tightlist
\item
  Paths : All received files are under folder csvfiles
  (./FinalCode/defaultInput/csvFiles)
\end{itemize}

\textbf{In this project, we generally have two paths to solve this
problem.} - Traditional Model - Deep Learning Process

    \hypertarget{business-questions-and-data-understandings}{%
\subsubsection{1.1 Business/ questions and data
understandings}\label{business-questions-and-data-understandings}}

    \begin{itemize}
\tightlist
\item
  Questions : Use current data from SAP to predict UNSPSC code
\item
  Approaches : Data Visulizations
\end{itemize}

    

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{A}\PY{o}{.}	\PY{n}{Business}\PY{o}{/} \PY{n}{questions} \PY{o+ow}{and} \PY{n}{data} \PY{n}{understandings}
        \PY{n}{B}\PY{o}{.}	\PY{n}{Data} \PY{n}{cleaning} \PY{o+ow}{and} \PY{n}{preparation} 
        \PY{n}{a}\PY{o}{.}	\PY{n}{Merged} \PY{n}{MARA} \PY{o+ow}{and} \PY{n}{MARC} \PY{n}{by} \PY{n}{matnr} \PY{n}{field}
        \PY{n}{b}\PY{o}{.}	\PY{n}{Checked} \PY{n}{fields} \PY{k}{with} \PY{n}{useful} \PY{n}{MARC}\PY{o}{/}\PY{n}{MARC} \PY{n}{dictionary}
        \PY{n}{c}\PY{o}{.}	\PY{n}{Cleaned} \PY{n}{null} \PY{n}{value}\PY{o}{/} \PY{n}{fixed} \PY{n}{value}
        \PY{n}{d}\PY{o}{.}	\PY{n}{Checked}\PY{o}{/} \PY{n}{cleaned} \PY{n}{STEUC} \PY{n}{value} \PY{n}{by} \PY{n}{comparing} \PY{k}{with} \PY{n}{valid} \PY{n}{STEUC} \PY{n}{value} \PY{n}{dictionary}
        \PY{n}{e}\PY{o}{.}	\PY{n}{Kept} \PY{n}{high} \PY{n}{quality} \PY{n}{data} \PY{p}{(}\PY{n}{Mmsta}\PY{o}{=}\PY{n}{P3}\PY{p}{)}
        \PY{n}{f}\PY{o}{.}	\PY{n}{Converted} \PY{n}{STEUC} \PY{n}{into} \PY{n}{Chapter} \PY{p}{(}\PY{n}{first} \PY{n}{two} \PY{n}{numbers}\PY{p}{)} \PY{o+ow}{and} \PY{n}{Position} \PY{p}{(}\PY{n}{first} \PY{n}{four} \PY{n}{numbers}\PY{p}{)}
        \PY{n}{g}\PY{o}{.}	\PY{n}{According} \PY{n}{to} \PY{n}{models}\PY{err}{â€™} \PY{n}{need}\PY{p}{,} \PY{n}{deleted} \PY{n}{Chapter} \PY{o+ow}{and} \PY{n}{Positions} \PY{n}{records} \PY{n}{based} \PY{n}{on} \PY{n}{frequency} \PY{n}{respectively}
        \PY{n}{C}\PY{o}{.}	\PY{n}{Model} \PY{n}{constructions} \PY{p}{(}\PY{n}{CHAID}\PY{p}{,} \PY{n}{classification} \PY{n}{tree}\PY{p}{,} \PY{n}{random} \PY{n}{forest}\PY{p}{,} \PY{n}{Neural} \PY{n}{network}\PY{p}{,} \PY{n}{SVM}\PY{p}{)}\PY{p}{:} \PY{n}{including} \PY{n}{models} \PY{n}{to} \PY{n}{predict} \PY{n}{Chapters}\PY{p}{,} \PY{n}{Positions} \PY{o+ow}{and} \PY{n}{STEUC} \PY{n}{field}
        \PY{n}{D}\PY{o}{.}	\PY{n}{Model} \PY{n}{evaluations} \PY{o+ow}{and} \PY{n}{optimizations}
        \PY{n}{E}\PY{o}{.}	\PY{n}{Discussion} \PY{k}{with} \PY{n}{findings}
\end{Verbatim}


    \hypertarget{modeling-introduction}{%
\subsubsection{1.0 Modeling Introduction}\label{modeling-introduction}}

    \begin{itemize}
\tightlist
\item
  Currently, all functions are in one model : mainFun.
\end{itemize}

    \hypertarget{main-function}{%
\paragraph{1.1 Main Function}\label{main-function}}

    mainFun Tree Structure :

--unspsc

\begin{verbatim}
|-- __init__ : Define the path
|-- dataPre :
|-- FeatureMerge
|-- Token
|-- TokenInput
|-- dataInput
|-- dataPre
|-- finalPrediction
|-- modelNetTrain
|-- modelPre
|-- modelTrain
|-- stagingFeature
|-- tokenSide
|-- wordEmbedding 
\end{verbatim}

    \hypertarget{initialization}{%
\paragraph{1.2 Initialization}\label{initialization}}

    \begin{itemize}
\tightlist
\item
  Step 1: import mainFunc module because all related functions are saved
  in this module.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ mainFun}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Step 2: Initilization

  \begin{itemize}
  \tightlist
  \item
    With all functions loaded, we can check all default paths and
    methods used in this module.
  \end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 1.Default Path}
\NormalTok{model }\OperatorTok{=}\NormalTok{ mainFun.unspsc() }
\CommentTok{# 2.Self-defined Path}
\NormalTok{filePath }\OperatorTok{=} \StringTok{'../FinalCode/defaultInput/csvFiles/UNSPSC Full Data Update 2.csv'}
\NormalTok{model }\OperatorTok{=}\NormalTok{ mainFun.unspsc(SapPath }\OperatorTok{=}\NormalTok{ filePath) }
\end{Highlighting}
\end{Shaded}
\end{itemize}

    \hypertarget{all-paths-for-initilization}{%
\paragraph{1.3 All paths for
initilization}\label{all-paths-for-initilization}}

    \begin{itemize}
\tightlist
\item
  weightsPath : path for all neuron network parameters
\item
  wordEmPath : embedding matrix after model training
\item
  GmdnPath: : all gmdn categories
\item
  PrhdaPath : current mapping file
\item
  SapPath : data directely from SAP System
\item
  EMBEDDING\_FILE : Path for loading fasttext file
\end{itemize}

    \hypertarget{code-demo}{%
\paragraph{1.4 Code Demo}\label{code-demo}}

    \hypertarget{code-demo-default}{%
\subparagraph{1.4.1 Code Demo Default}\label{code-demo-default}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{c+c1}{\PYZsh{} Initial}
        \PY{k+kn}{import} \PY{n+nn}{mainFun}
        \PY{n}{model} \PY{o}{=} \PY{n}{mainFun}\PY{o}{.}\PY{n}{unspsc}\PY{p}{(}\PY{p}{)}
        \PY{n}{filterAll}\PY{p}{,} \PY{n}{y\PYZus{}train} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{dataPre}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Using TensorFlow backend.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Data Preparation Finished

    \end{Verbatim}

    \hypertarget{code-demo-default}{%
\subparagraph{1.4.2 Code Demo Default}\label{code-demo-default}}

\begin{itemize}
\tightlist
\item
  Use new documents to create new objects.
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{c+c1}{\PYZsh{} folder path}
        \PY{n}{rootPath} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/Users/ValarMorghulis/Johnson\PYZus{}Johnson/FinalCode/}\PY{l+s+s1}{\PYZsq{}}
        \PY{c+c1}{\PYZsh{} Data From SAP System}
        \PY{n}{SapPath} \PY{o}{=} \PY{n}{rootPath} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{defaultInput/csvFiles/UNSPSC Full Data Update 2.csv}\PY{l+s+s1}{\PYZsq{}}
        \PY{c+c1}{\PYZsh{} PRHDA File}
        \PY{n}{PrhdaPath}\PY{o}{=} \PY{n}{rootPath} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{defaultInput/csvFiles/Prhda.csv}\PY{l+s+s1}{\PYZsq{}}
        \PY{c+c1}{\PYZsh{} GMDN Description}
        \PY{n}{GmdnPath} \PY{o}{=} \PY{n}{rootPath} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{defaultInput/csvFiles/GMDN\PYZus{}desp.csv}\PY{l+s+s1}{\PYZsq{}}
        \PY{c+c1}{\PYZsh{} Fasttest WordEmbedding File}
        \PY{n}{embedPath} \PY{o}{=} \PY{n}{rootPath} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{defaultInput/wordEmbeddingMartix/crawl\PYZhy{}300d\PYZhy{}2M.vec}\PY{l+s+s1}{\PYZsq{}}
        \PY{c+c1}{\PYZsh{} All pre\PYZhy{}trained parameters }
        \PY{n}{weightsPath} \PY{o}{=} \PY{n}{rootPath} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{defaultInput/preTrainedWordEmbed/}\PY{l+s+s1}{\PYZsq{}}
        \PY{c+c1}{\PYZsh{} All pre\PYZhy{}trained model wordembedding files}
        \PY{n}{wordEmPath} \PY{o}{=} \PY{n}{rootPath} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{defaultInput/wordEmbeddingMartix/}\PY{l+s+s1}{\PYZsq{}}
        
        \PY{c+c1}{\PYZsh{} Initial}
        \PY{k+kn}{import} \PY{n+nn}{mainFun}
        \PY{n}{model} \PY{o}{=} \PY{n}{mainFun}\PY{o}{.}\PY{n}{unspsc}\PY{p}{(}\PY{n}{SapPath} \PY{o}{=} \PY{n}{SapPath}\PY{p}{,}
                               \PY{n}{PrhdaPath}\PY{o}{=} \PY{n}{PrhdaPath}\PY{p}{,}
                               \PY{n}{GmdnPath} \PY{o}{=} \PY{n}{GmdnPath}\PY{p}{,}
                               \PY{n}{embedPath} \PY{o}{=} \PY{n}{embedPath}\PY{p}{,}
                               \PY{n}{weightsPath} \PY{o}{=} \PY{n}{weightsPath}\PY{p}{,}
                               \PY{n}{wordEmPath} \PY{o}{=} \PY{n}{wordEmPath}\PY{p}{)}
        \PY{n}{filterAll}\PY{p}{,} \PY{n}{y\PYZus{}train} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{dataPre}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Data Preparation Finished

    \end{Verbatim}

    \hypertarget{first-data-glance}{%
\paragraph{1.5 First Data Glance}\label{first-data-glance}}

    Given all data pathes, we merge all data together using \textbf{inner
join}. All actions we took for our data. - 1.Drop lines with Null GMDN
name, Material Description and Prdha Description. - 2.Uniform all Prdha
code. (e.g Some Prdha codes are not 18 digits. We use a function to make
all codes 18 digits.)

\textbf{Extra Explaination:}

We only select limited features from the table:

\begin{itemize}
\tightlist
\item
  Production Dimension : Breit, Brgew, Hoehe, Laeng, Volum, Ntgew
  (width, length, height\ldots{})
\item
  Text Fields : Material Description, Gmdnptdefinition (long),
  Gmdnptname (short), Minor\_name, Major\_name, Material (all text)
\item
  Digits : Ean11 (GTIN), Unspsc, Prdha
\item
  Others : Zzwerks (location), Material\_top3 (first three chars of
  material description)
\end{itemize}

\textbf{Related Modules:} * dataPre : Create and prepare all required
data * prdha\_zero : Change all prdha code to 18 digits. (fill 0 in the
beginning)

    \emph{Part of the data:}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{n}{filterAll}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,}\PY{p}{:}\PY{p}{]}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}3}]:} Breit                                                                   0
        Brgew                                                                   1
        Hoehe                                                                   0
        Laeng                                                                   0
        Volum                                                                   0
        Zzwerks                                                              CA02
        Ntgew                                                                   1
        Material Description                                     NORIAN DRILLABLE
        Material                                                   07.704.003S-US
        Ean11                                                          1.0887e+13
        Gmdnptdefinition        A sterile bioabsorbable device made of synthet{\ldots}
        Gmdnptname                                 Bone matrix implant, synthetic
        Unspsc                                                           42291501
        Prdha                                                  055078377837047824
        Minor\_name                                                   Biomaterials
        Major\_name                                                 Synthes Trauma
        Material\_top3                                                         07.
        Name: 0, dtype: object
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{n}{filterAll}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{:}\PY{l+m+mi}{15}\PY{p}{]}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}4}]:}                                     Gmdnptdefinition  \textbackslash{}
        0  A sterile bioabsorbable device made of synthet{\ldots}   
        1  A sterile bioabsorbable device made of synthet{\ldots}   
        2  A sterile bioabsorbable device made of synthet{\ldots}   
        3  A sterile bioabsorbable device made of synthet{\ldots}   
        4  A sterile bioabsorbable device made of synthet{\ldots}   
        
                               Gmdnptname    Unspsc               Prdha    Minor\_name  
        0  Bone matrix implant, synthetic  42291501  055078377837047824  Biomaterials  
        1  Bone matrix implant, synthetic  42291501  055078377837047824  Biomaterials  
        2  Bone matrix implant, synthetic  42291501  055078377837047824  Biomaterials  
        3  Bone matrix implant, synthetic  42291501  055078377837047824  Biomaterials  
        4  Bone matrix implant, synthetic  42291501  055078377837047824  Biomaterials  
\end{Verbatim}
            
    \hypertarget{modeling}{%
\subsubsection{2.0 Modeling}\label{modeling}}

    This part is very complicated. Generally speaking, it can be divided
into two parts. - Model Training - Model Output

    \hypertarget{modeling-training}{%
\subsubsection{2.1 Modeling Training}\label{modeling-training}}

    Currently, all modules have been encapsulated into the final model
\textbf{stagingFeature}.

\textbf{Step 1: Sentence to Words} - At first, Keras text mining tool
will parse each sentence and then split them into words. - Related
Modules : Token, TokenInput, tokenSide - We have \textbf{3} models
according to different text. This step will create different words of
bags. The number of each bag is different because some text has more
different words (more information).

\textbf{Step 2: Word Embedding} - Next, Fasttest will change these words
into matrix. The embedding matrix will be the first layer for neutral
network. - Related Modules : wordEmbedding

\textbf{Step 3: RNN} - We use very complex techniques in the modeling
part. For Natural Language Processing, we use RNN GRU. For detailed
model part, see example below.

\textbf{Step 4 : Encapsulation} - All these functions are encapsulated
into one module. To simplify this training process, changing some
parameters can train the model. - Advanced Technique: we use
\textbf{autoencoder} for informaiton extraction and compression. As a
result, the output will be the inner layer of RNN. - Related Module :
modelTrain

    \textbf{Example: GMDN} - Use pre-cleaned data : filterAl(x), y\_train(y)
- Text Type : gmdn - Pre-trained : False (use new data to train the
model) - Summay : True (show training framework) - epoches : juse epoch
(50-60s per epoch, more epoches more accurate) - Input : False (this is
designed for interface)

If choosing to train, folder ``preTrainedWordEmbed'' will have a new
file with beginning ``New''

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{n}{gmdn\PYZus{}output} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{modelTrain}\PY{p}{(}\PY{n}{filterAll}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gmdn}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                       \PY{n}{Pre\PYZus{}trained}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,}\PY{n}{Summary}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{epochs} \PY{o}{=} \PY{l+m+mi}{20}\PY{p}{,}\PY{n}{Input}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
embedding\_2 (Embedding)      (None, None, 300)         210000    
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
spatial\_dropout1d\_2 (Spatial (None, None, 300)         0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
bidirectional\_2 (Bidirection (None, None, 160)         182880    
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
global\_average\_pooling1d\_2 ( (None, 160)               0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_3 (Dense)              (None, 100)               16100     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_4 (Dense)              (None, 73)                7373      
=================================================================
Total params: 416,353
Trainable params: 416,353
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Train on 16560 samples, validate on 4141 samples
Epoch 1/20
16560/16560 [==============================] - 67s 4ms/step - loss: 3.4889 - acc: 0.2052 - val\_loss: 3.0782 - val\_acc: 0.1599
Epoch 2/20
16560/16560 [==============================] - 62s 4ms/step - loss: 2.8216 - acc: 0.2739 - val\_loss: 2.5823 - val\_acc: 0.4303
Epoch 3/20
16560/16560 [==============================] - 60s 4ms/step - loss: 2.3762 - acc: 0.4685 - val\_loss: 2.2454 - val\_acc: 0.4465
Epoch 4/20
16560/16560 [==============================] - 62s 4ms/step - loss: 2.1144 - acc: 0.4914 - val\_loss: 1.9849 - val\_acc: 0.5506
Epoch 5/20
16560/16560 [==============================] - 60s 4ms/step - loss: 1.8753 - acc: 0.5421 - val\_loss: 1.7726 - val\_acc: 0.5506
Epoch 6/20
16560/16560 [==============================] - 65s 4ms/step - loss: 1.6804 - acc: 0.5515 - val\_loss: 1.5909 - val\_acc: 0.5883
Epoch 7/20
16560/16560 [==============================] - 60s 4ms/step - loss: 1.5119 - acc: 0.6002 - val\_loss: 1.4426 - val\_acc: 0.6141
Epoch 8/20
16560/16560 [==============================] - 62s 4ms/step - loss: 1.3699 - acc: 0.6183 - val\_loss: 1.3145 - val\_acc: 0.6204
Epoch 9/20
16560/16560 [==============================] - 62s 4ms/step - loss: 1.2556 - acc: 0.6428 - val\_loss: 1.2107 - val\_acc: 0.6629
Epoch 10/20
16560/16560 [==============================] - 59s 4ms/step - loss: 1.1561 - acc: 0.6736 - val\_loss: 1.1197 - val\_acc: 0.6742
Epoch 11/20
16560/16560 [==============================] - 58s 4ms/step - loss: 1.0702 - acc: 0.6922 - val\_loss: 1.0318 - val\_acc: 0.7064
Epoch 12/20
16560/16560 [==============================] - 60s 4ms/step - loss: 0.9913 - acc: 0.7123 - val\_loss: 0.9605 - val\_acc: 0.7315
Epoch 13/20
16560/16560 [==============================] - 67s 4ms/step - loss: 0.9218 - acc: 0.7316 - val\_loss: 0.8923 - val\_acc: 0.7409
Epoch 14/20
16560/16560 [==============================] - 60s 4ms/step - loss: 0.8606 - acc: 0.7437 - val\_loss: 0.8343 - val\_acc: 0.7612
Epoch 15/20
16560/16560 [==============================] - 59s 4ms/step - loss: 0.8008 - acc: 0.7626 - val\_loss: 0.7748 - val\_acc: 0.7633
Epoch 16/20
16560/16560 [==============================] - 61s 4ms/step - loss: 0.7434 - acc: 0.7774 - val\_loss: 0.7192 - val\_acc: 0.8020
Epoch 17/20
16560/16560 [==============================] - 59s 4ms/step - loss: 0.6879 - acc: 0.7997 - val\_loss: 0.6590 - val\_acc: 0.8042
Epoch 18/20
16560/16560 [==============================] - 60s 4ms/step - loss: 0.6332 - acc: 0.8085 - val\_loss: 0.6145 - val\_acc: 0.8008
Epoch 19/20
16560/16560 [==============================] - 62s 4ms/step - loss: 0.5863 - acc: 0.8402 - val\_loss: 0.5671 - val\_acc: 0.8476
Epoch 20/20
16560/16560 [==============================] - 59s 4ms/step - loss: 0.5449 - acc: 0.8510 - val\_loss: 0.5310 - val\_acc: 0.8614
20701/20701 [==============================] - 24s 1ms/step

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{material\PYZus{}output} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{modelTrain}\PY{p}{(}\PY{n}{filterAll}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{material}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                       \PY{n}{Pre\PYZus{}trained}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,}\PY{n}{Summary}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{epochs} \PY{o}{=} \PY{l+m+mi}{20}\PY{p}{,}\PY{n}{Input}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
embedding\_3 (Embedding)      (None, None, 300)         1200000   
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
spatial\_dropout1d\_3 (Spatial (None, None, 300)         0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
bidirectional\_3 (Bidirection (None, None, 160)         182880    
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
global\_average\_pooling1d\_3 ( (None, 160)               0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_5 (Dense)              (None, 100)               16100     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_6 (Dense)              (None, 73)                7373      
=================================================================
Total params: 1,406,353
Trainable params: 1,406,353
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Train on 16560 samples, validate on 4141 samples
Epoch 1/20
16560/16560 [==============================] - 65s 4ms/step - loss: 3.5717 - acc: 0.1647 - val\_loss: 3.1135 - val\_acc: 0.1599
Epoch 2/20
 4608/16560 [=======>{\ldots}] - ETA: 41s - loss: 3.0833 - acc: 0.2201
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{prdha\PYZus{}output} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{modelTrain}\PY{p}{(}\PY{n}{filterAll}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{prdha}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                       \PY{n}{Pre\PYZus{}trained}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,}\PY{n}{Summary}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{epochs} \PY{o}{=} \PY{l+m+mi}{20}\PY{p}{,}\PY{n}{Input}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}26}]:} \PY{n}{gmdn\PYZus{}output}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}26}]:} array([[ 0.42574066,  0.22168098, -0.83287275, {\ldots},  0.851093  ,
                  0.75264883, -0.48427856],
                [ 0.42574066,  0.22168098, -0.83287275, {\ldots},  0.851093  ,
                  0.75264883, -0.48427856],
                [ 0.42574066,  0.22168098, -0.83287275, {\ldots},  0.851093  ,
                  0.75264883, -0.48427856],
                {\ldots},
                [ 0.42580032,  0.21798937, -0.8328871 , {\ldots},  0.8473034 ,
                  0.7476784 , -0.47957227],
                [ 0.42580032,  0.21798937, -0.8328871 , {\ldots},  0.8473034 ,
                  0.7476784 , -0.47957227],
                [ 0.42580032,  0.21798937, -0.8328871 , {\ldots},  0.8473034 ,
                  0.7476784 , -0.47957227]], dtype=float32)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{n}{gmdn\PYZus{}output}\PY{o}{.}\PY{n}{shape} \PY{c+c1}{\PYZsh{} (row,column)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}27}]:} (20701, 160)
\end{Verbatim}
            
    \hypertarget{pre-trained-model}{%
\subsubsection{2.2 Pre-trained Model}\label{pre-trained-model}}

    Pre-trained model is also provied in this part so that pre-trained
parameters can be used for prediction.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{n}{gmdn\PYZus{}output}\PY{p}{,} \PY{n}{material\PYZus{}output}\PY{p}{,} \PY{n}{prdha\PYZus{}output} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{stagingFeature}\PY{p}{(}\PY{n}{filterAll}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{p}{,}\PY{n}{Pre\PYZus{}trained}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,}\PY{n}{Summary}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,}\PY{n}{epochs}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{n}{gmdn\PYZus{}output}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}18}]:} array([[0.5001244 , 0.5002361 , 0.5005077 , {\ldots}, 0.49951077, 0.4995304 ,
                 0.5007937 ],
                [0.5001244 , 0.5002361 , 0.5005077 , {\ldots}, 0.49951077, 0.4995304 ,
                 0.5007937 ],
                [0.5001244 , 0.5002361 , 0.5005077 , {\ldots}, 0.49951077, 0.4995304 ,
                 0.5007937 ],
                {\ldots},
                [0.50263643, 0.4967825 , 0.50356215, {\ldots}, 0.49880517, 0.50083315,
                 0.49956587],
                [0.50246525, 0.49643865, 0.50377476, {\ldots}, 0.49867803, 0.50098616,
                 0.49984753],
                [0.50263786, 0.4966278 , 0.5035604 , {\ldots}, 0.49851787, 0.50113136,
                 0.499635  ]], dtype=float32)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{n}{gmdn\PYZus{}output}\PY{o}{.}\PY{n}{shape} \PY{c+c1}{\PYZsh{} (row,column)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}28}]:} (20701, 160)
\end{Verbatim}
            
    \hypertarget{merge-all-features}{%
\subsubsection{3.0 Merge All Features}\label{merge-all-features}}

    \begin{itemize}
\tightlist
\item
  This part is very simple. Just merge all previous word embedding
  matrix and other features such product dimensions, locations and other
  information
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}36}]:} \PY{n}{featuresReady} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{FeatureMerge}\PY{p}{(}\PY{n}{gmdn\PYZus{}output}\PY{p}{,}\PY{n}{material\PYZus{}output}\PY{p}{,}\PY{n}{prdha\PYZus{}output}\PY{p}{,}\PY{n}{filterAll}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}37}]:} \PY{n}{featuresReady}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{3}\PY{p}{,}\PY{p}{:}\PY{l+m+mi}{8}\PY{p}{]}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}37}]:}    Breit  Brgew  Hoehe  Laeng  Volum  Location\_BR06  Location\_BR08  \textbackslash{}
         0    0.0    1.0    0.0    0.0    0.0              0              0   
         1    0.0    1.0    0.0    0.0    0.0              0              0   
         2    0.0    1.0    0.0    0.0    0.0              0              0   
         
            Location\_CA02  
         0              1  
         1              1  
         2              1  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}35}]:} \PY{n}{featuresReady}\PY{o}{.}\PY{n}{shape} \PY{c+c1}{\PYZsh{} (row,column)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}35}]:} (20701, 477)
\end{Verbatim}
            
    \hypertarget{boosting-tree-prediction}{%
\subsubsection{4.0 Boosting Tree
Prediction}\label{boosting-tree-prediction}}

    \begin{itemize}
\tightlist
\item
  With all previous features, final model is XGBoost Boosting Tree
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}39}]:} \PY{n}{finalPrediction} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{finalPrediction}\PY{p}{(}\PY{n}{featuresReady}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{num\PYZus{}round}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}44}]:} \PY{n}{finalPrediction}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}44}]:} (20701,)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}45}]:} \PY{n}{y\PYZus{}train}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}45}]:} (20701,)
\end{Verbatim}
            
    \hypertarget{appendix-reference-materials}{%
\subsubsection{Appendix : Reference
Materials}\label{appendix-reference-materials}}

\begin{itemize}
\tightlist
\item
  Books: Flask Web Development: Developing Web Applications with Python
\item
  Tech : plotly, Dash
\end{itemize}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
